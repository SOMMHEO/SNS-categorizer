{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66c36756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ehddl\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\sns-categorizer-wO1G7-CE-py3.11\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "# from torch.utils.data import Dataset, DataLoader -> datasets 라이브러리랑 충돌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54cd86f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 3050\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count()) \n",
    "print(torch.cuda.get_device_name(0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de28eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch==2.5.1+cu121 --index-url https://download.pytorch.org/whl/cu121\n",
    "# poetry run pip install torch==2.5.1+cu121 --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "825d6343",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/ehddl/Desktop/업무/code/sns-categorizer/sns-category-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167892c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media_cn_cleaned</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>휴가 돌려죠</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>관종들 릴스 릴스타그램 릴스초보</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>날이 좋아서</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>행복했던 9월 고마워</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>협찬 동결건조야채블럭 1개로 13종의 보라야채와 유산균 섭취가능 보라색 안토시아닌이...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39925</th>\n",
       "      <td>아빠들의 일사분란함은 가족애 였다 어제 캠핑하는데 전혀 예상치 못했던 비바람 돌풍이...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39926</th>\n",
       "      <td>광고 식용유 없이 전을 굽는다고 풀무원 철판수제전 3종세트 철판 바삭감자채전 철판 ...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39927</th>\n",
       "      <td>제품제공 이걸 소개할 수 있어 영광입니다 가장 카고스럽게 보다 더 대담하게 카고컨테...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39928</th>\n",
       "      <td>제품제공 이제 남편들이 요리 다하겠습니다 아내님들 남편에게 식스볼트 듀라박스만 사주...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39929</th>\n",
       "      <td>광고 튼튼함을 의심해서 죄송합니다 와이 캐리어 뭐지 새거 받자마자 3m 이상에서 떨...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39863 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        media_cn_cleaned  label_id\n",
       "0                                                 휴가 돌려죠        19\n",
       "1                                      관종들 릴스 릴스타그램 릴스초보        21\n",
       "2                                                 날이 좋아서        19\n",
       "3                                            행복했던 9월 고마워        19\n",
       "4      협찬 동결건조야채블럭 1개로 13종의 보라야채와 유산균 섭취가능 보라색 안토시아닌이...         8\n",
       "...                                                  ...       ...\n",
       "39925  아빠들의 일사분란함은 가족애 였다 어제 캠핑하는데 전혀 예상치 못했던 비바람 돌풍이...        25\n",
       "39926  광고 식용유 없이 전을 굽는다고 풀무원 철판수제전 3종세트 철판 바삭감자채전 철판 ...        25\n",
       "39927  제품제공 이걸 소개할 수 있어 영광입니다 가장 카고스럽게 보다 더 대담하게 카고컨테...        25\n",
       "39928  제품제공 이제 남편들이 요리 다하겠습니다 아내님들 남편에게 식스볼트 듀라박스만 사주...        25\n",
       "39929  광고 튼튼함을 의심해서 죄송합니다 와이 캐리어 뭐지 새거 받자마자 3m 이상에서 떨...        17\n",
       "\n",
       "[39863 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"tests/final_fine_tuning_data.csv\", index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cd22dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size= 0.2, stratify=data['label_id'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "868e111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model & toknizer loading\n",
    "\n",
    "model_name = \"kykim/bert-kor-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "## 모델이 bert 계열이고, 속도가 중요하면 BertTkenizerFast\n",
    "## 모델을 자주 비꾸거나 여러 모델 실험할 계획이면 AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08123c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 31890/31890 [00:02<00:00, 10631.29 examples/s]\n",
      "Map: 100%|██████████| 7973/7973 [00:00<00:00, 11647.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# huggingface의 datasets.Dataset을 사용하는 방식\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train' : Dataset.from_pandas(train),\n",
    "    'test' : Dataset.from_pandas(test)\n",
    "})\n",
    "\n",
    "# preprocessing\n",
    "\n",
    "def tokenize_fn(ex):\n",
    "    return tokenizer(ex[\"media_cn_cleaned\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "dataset = dataset.map(tokenize_fn, batched=True)\n",
    "dataset = dataset.rename_column(\"label_id\", \"label\")\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c0d82d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['media_cn_cleaned', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 31890\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f864582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at kykim/bert-kor-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# setting model\n",
    "\n",
    "num_labels = data['label_id'].nunique()\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    use_safetensors=True # gpu 버전 사용 시 추가\n",
    ")\n",
    "\n",
    "# torch gpu버전을 pip install torch==2.5.1+cu121 --index-url https://download.pytorch.org/whl/cu121로 설치\n",
    "# huggingface transformer 라이브러리가 pytorch 2.6 미만 버전은 보안 이슈로 강제로 차단하는데, gpu 버전의 torch는 현재 pip로 설치가 불가능. 따라서 우회하는 user_safetensor를 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43801909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting trainer\n",
    "# !pip install accelerate>=0.26.0\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"finetune-bert-kor\",\n",
    "    eval_strategy=\"epoch\", # evaluation_strategy -> eval_strategy\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    save_total_limit=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc640b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(axis=-1)\n",
    "    labels = p.label_ids\n",
    "    return {\"accuracy\": accuracy_score(labels, preds)}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e3a4619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5982' max='5982' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5982/5982 45:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.047000</td>\n",
       "      <td>1.023184</td>\n",
       "      <td>0.719303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.979414</td>\n",
       "      <td>0.731720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.632400</td>\n",
       "      <td>0.990934</td>\n",
       "      <td>0.732096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5982, training_loss=0.902096227035599, metrics={'train_runtime': 2742.3864, 'train_samples_per_second': 34.886, 'train_steps_per_second': 2.181, 'total_flos': 6294314713052160.0, 'train_loss': 0.902096227035599, 'epoch': 3.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25506b5d",
   "metadata": {},
   "source": [
    "##### Using Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823d0c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # huggingface가 아니라 pytorch library 사용 시 방법\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# class TokenDataset(Dataset):\n",
    "  \n",
    "#     def __init__(self, dataframe, model_name):\n",
    "#         # sentence, label 컬럼으로 구성된 데이터프레임 전달\n",
    "#         self.data = dataframe        \n",
    "#         # Huggingface 토크나이저 생성\n",
    "#         # self.tokenizer = BertTokenizerFast.from_pretrained(tokenizer_pretrained)\n",
    "#         self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "  \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "  \n",
    "#     def __getitem__(self, idx):\n",
    "#         sentence = self.data.iloc[idx]['document']\n",
    "#         label = self.data.iloc[idx]['label']\n",
    "\n",
    "#         # 토큰화 처리\n",
    "#         tokens = self.tokenizer(\n",
    "#             sentence,                # 1개 문장 \n",
    "#             return_tensors='pt',     # 텐서로 반환\n",
    "#             truncation=True,         # 잘라내기 적용\n",
    "#             padding='max_length',    # 패딩 적용\n",
    "#             add_special_tokens=True  # 스페셜 토큰 적용\n",
    "#         )\n",
    "\n",
    "#         input_ids = tokens['input_ids'].squeeze(0)           # 2D -> 1D\n",
    "#         attention_mask = tokens['attention_mask'].squeeze(0) # 2D -> 1D\n",
    "#         token_type_ids = torch.zeros_like(attention_mask)\n",
    "\n",
    "#         # input_ids, attention_mask, token_type_ids 이렇게 3가지 요소를 반환하도록 합니다.\n",
    "#         # input_ids: 토큰\n",
    "#         # attention_mask: 실제 단어가 존재하면 1, 패딩이면 0 (패딩은 0이 아닐 수 있습니다)\n",
    "#         # token_type_ids: 문장을 구분하는 id. 단일 문장인 경우에는 전부 0\n",
    "#         return {\n",
    "#             'input_ids': input_ids,\n",
    "#             'attention_mask': attention_mask, \n",
    "#             'token_type_ids': token_type_ids,\n",
    "#         }, torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaae1057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train, test 데이터셋 생성\n",
    "# train_data = TokenDataset(train, model_name)\n",
    "# test_data = TokenDataset(test, model_name)\n",
    "\n",
    "# # DataLoader로 이전에 생성한 Dataset를 지정하여, batch 구성, shuffle, num_workers 등을 설정합니다.\n",
    "# train_loader = DataLoader(train_data, batch_size=8, shuffle=True, num_workers=8)\n",
    "# test_loader = DataLoader(test_data, batch_size=8, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c291e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1개의 batch 꺼내기\n",
    "# inputs, labels = next(iter(train_loader))\n",
    "\n",
    "# # 데이터셋을 device 설정\n",
    "# inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "# labels.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sns-categorizer-wO1G7-CE-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
